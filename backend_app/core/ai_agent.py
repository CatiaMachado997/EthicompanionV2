"""
Agente AI Principal
Integra LLM com ferramenta            # Comentar OpenAI temporariamente para usar Gemini
            # if openai_api_key:
            #     self.llm = ChatOpenAI(
            #         model="gpt-3.5-turbo",  # Modelo mais acessÃ­vel
            #         temperature=0.7,
            #         max_tokens=1000,
            #         openai_api_key=openai_api_key
            #     )
            #     print("âœ… DEBUG - OpenAI GPT-3.5-turbo inicializado com sucesso")
            #     logger.info("âœ… LLM OpenAI inicializado")
            #     returna de memÃ³ria para conversas inteligentes
"""

import asyncio
import logging
from typing import Dict, Any, Optional, List
import os
from datetime import datetime

# Imports para LLM e ferramentas
try:
    from langchain_openai import ChatOpenAI
    from langchain_google_genai import ChatGoogleGenerativeAI
    from langchain.schema import HumanMessage, SystemMessage
    from langchain.tools import Tool
    from langchain.agents import AgentExecutor, create_openai_functions_agent
    from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
    from langchain.memory import ConversationBufferWindowMemory
except ImportError as e:
    logging.warning(f"âš ï¸ Alguns imports do LangChain falharam: {e}")

logger = logging.getLogger(__name__)

class EthicCompanionAgent:
    """
    Agente AI principal que combina LLM com ferramentas e sistema de memÃ³ria
    """
    
    def __init__(self):
        """Inicializa o agente com LLM e ferramentas"""
        self.llm = None
        self.agent_executor = None
        self.tools = []
        self._initialize_llm()
        self._initialize_tools()
        self._initialize_agent()
    
    def _initialize_llm(self):
        """Inicializa o modelo de linguagem (Google Gemini - OpenAI temporariamente desativado)"""
        try:
            # Debug: Verificar chaves API
            openai_api_key = os.getenv("OPENAI_API_KEY")
            google_api_key = os.getenv("GOOGLE_API_KEY")
            
            print(f"ğŸ” DEBUG - OpenAI API Key: {'âœ… Carregada' if openai_api_key else 'âŒ NÃ£o encontrada'}")
            print(f"ğŸ” DEBUG - Google API Key: {'âœ… Carregada' if google_api_key else 'âŒ NÃ£o encontrada'}")
            
            # Comentar OpenAI temporariamente para usar Gemini
            # if openai_api_key:
            #     self.llm = ChatOpenAI(
            #         model="gpt-3.5-turbo",  # Modelo mais acessÃ­vel
            #         temperature=0.7,
            #         max_tokens=1000,
            #         openai_api_key=openai_api_key
            #     )
            #     print("âœ… DEBUG - OpenAI GPT-3.5-turbo inicializado com sucesso")
            #     logger.info("âœ… LLM OpenAI inicializado")
            #     return
                
        except Exception as e:
            print(f"âš ï¸ DEBUG - OpenAI desativado temporariamente: {e}")
            logger.warning(f"âš ï¸ OpenAI desativado temporariamente: {e}")
        
        try:
            # Usar Google Gemini como principal
            if google_api_key:
                self.llm = ChatGoogleGenerativeAI(
                    model="gemini-1.5-flash",  # Modelo mais recente disponÃ­vel
                    temperature=0.7,
                    google_api_key=google_api_key
                )
                print("âœ… DEBUG - Google Gemini 1.5 Flash inicializado como LLM principal")
                logger.info("âœ… LLM Google Gemini inicializado")
                return
                
        except Exception as e:
            print(f"âŒ DEBUG - Falha ao inicializar Gemini: {e}")
            logger.warning(f"âŒ Falha ao inicializar Gemini: {e}")
        
        # Se nenhum LLM foi inicializado
        print("âŒ DEBUG - NENHUM LLM DISPONÃVEL - USANDO FALLBACK")
        logger.error("âŒ Nenhum LLM disponÃ­vel")
        self.llm = None
    
    def _initialize_tools(self):
        """Inicializa ferramentas disponÃ­veis para o agente"""
        
        # Ferramenta de pesquisa web (Tavily)
        if os.getenv("TAVILY_API_KEY"):
            try:
                web_search_tool = Tool(
                    name="web_search",
                    description="Pesquisa informaÃ§Ãµes atuais na web. Usa quando precisas de informaÃ§Ãµes recentes ou especÃ­ficas que nÃ£o tens.",
                    func=self._web_search
                )
                self.tools.append(web_search_tool)
                logger.info("âœ… Ferramenta de pesquisa web ativada")
            except Exception as e:
                logger.warning(f"âš ï¸ Falha ao configurar pesquisa web: {e}")
        
        # Ferramenta de anÃ¡lise Ã©tica
        ethical_analysis_tool = Tool(
            name="ethical_analysis",
            description="Analisa questÃµes Ã©ticas complexas usando princÃ­pios de filosofia moral e Ã©tica aplicada.",
            func=self._ethical_analysis
        )
        self.tools.append(ethical_analysis_tool)
        
        # Ferramenta de reflexÃ£o pessoal
        personal_reflection_tool = Tool(
            name="personal_reflection",
            description="Facilita reflexÃ£o pessoal e autoconhecimento atravÃ©s de perguntas guiadas.",
            func=self._personal_reflection
        )
        self.tools.append(personal_reflection_tool)
        
        logger.info(f"âœ… {len(self.tools)} ferramentas inicializadas")
    
    def _initialize_agent(self):
        """Inicializa o agente executivo com LLM e ferramentas"""
        if not self.llm:
            logger.error("âŒ NÃ£o Ã© possÃ­vel criar agente sem LLM")
            return
        
        try:
            # Prompt do sistema para o agente
            system_prompt = """Ã‰s o Ethic Companion, um assistente de IA especializado em Ã©tica, filosofia e desenvolvimento pessoal.

A tua missÃ£o Ã© ajudar as pessoas a:
1. ğŸ¤” Refletir sobre questÃµes Ã©ticas complexas
2. ğŸŒ± Desenvolver um pensamento crÃ­tico mais profundo  
3. ğŸ§­ Navegar dilemas morais com sabedoria
4. ğŸ’­ Facilitar autoconhecimento e crescimento pessoal

CaracterÃ­sticas da tua personalidade:
- EmpÃ¡tico e compreensivo
- Questionador sem ser julgmental
- SÃ¡bio mas humilde
- PrÃ¡tico nas sugestÃµes
- Respeitoso com todas as perspetivas

Usa as ferramentas disponÃ­veis quando apropriado:
- web_search: Para informaÃ§Ãµes atuais ou especÃ­ficas
- ethical_analysis: Para questÃµes Ã©ticas complexas
- personal_reflection: Para facilitar autoconhecimento

Responde sempre em portuguÃªs e mantÃ©m um tom caloroso e acessÃ­vel."""

            # Tentar criar agente com ferramentas (se disponÃ­veis)
            if hasattr(self, 'tools') and self.tools:
                try:
                    # Template do prompt compatÃ­vel com Gemini
                    prompt = ChatPromptTemplate.from_messages([
                        ("system", system_prompt),
                        MessagesPlaceholder(variable_name="chat_history"),
                        ("human", "{input}"),
                        MessagesPlaceholder(variable_name="agent_scratchpad")
                    ])
                    
                    # Tentar criar agente OpenAI functions (pode funcionar com Gemini)
                    agent = create_openai_functions_agent(self.llm, self.tools, prompt)
                    self.agent_executor = AgentExecutor(
                        agent=agent,
                        tools=self.tools,
                        verbose=True,
                        handle_parsing_errors=True,
                        max_iterations=3,
                        return_intermediate_steps=True
                    )
                    logger.info("âœ… Agente com ferramentas inicializado")
                    print("âœ… DEBUG - Agente com ferramentas criado com sucesso")
                    
                except Exception as e:
                    print(f"âš ï¸ DEBUG - Agente com ferramentas falhou, usando LLM direto: {e}")
                    logger.warning(f"âš ï¸ Falha ao criar agente com ferramentas: {e}")
                    # Fallback para LLM simples
                    self.agent_executor = None
            else:
                self.agent_executor = None
                logger.info("âœ… LLM simples inicializado (sem ferramentas)")
                print("âœ… DEBUG - LLM simples configurado")
                
        except Exception as e:
            print(f"âŒ DEBUG - Erro crÃ­tico ao inicializar agente: {e}")
            logger.error(f"âŒ Erro ao inicializar agente: {e}")
            self.agent_executor = None
    
    async def process_message(self, message: str, session_id: str) -> Dict[str, Any]:
        """
        Processa uma mensagem do utilizador e retorna resposta
        
        Args:
            message: Mensagem do utilizador
            session_id: ID da sessÃ£o para contexto
            
        Returns:
            Dict com resposta e metadados
        """
        try:
            start_time = datetime.now()
            
            # Se temos agente com ferramentas
            if self.agent_executor:
                try:
                    result = await asyncio.get_event_loop().run_in_executor(
                        None, 
                        lambda: self.agent_executor.invoke({
                            "input": message,
                            "chat_history": []  # MemÃ³ria gerida externamente
                        })
                    )
                    
                    response_text = result.get("output", "Desculpa, nÃ£o consegui processar a tua mensagem.")
                    tools_used = self._extract_tools_used(result)
                    
                except Exception as e:
                    print(f"ğŸš¨ DEBUG - ERRO NO AGENTE EXECUTOR: {e}")
                    print(f"ğŸš¨ DEBUG - TIPO DE ERRO: {type(e).__name__}")
                    logger.error(f"âŒ Erro no agente executor: {e}")
                    # Fallback para LLM direto
                    response_text = await self._direct_llm_response(message)
                    tools_used = []
            
            # Se sÃ³ temos LLM direto
            elif self.llm:
                response_text = await self._direct_llm_response(message)
                tools_used = []
            
            # Se nÃ£o temos nenhum LLM
            else:
                response_text = self._fallback_response(message)
                tools_used = []
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            return {
                "response": response_text,
                "session_id": session_id,
                "processing_time": processing_time,
                "tools_used": tools_used,
                "llm_type": self._get_llm_type(),
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"âŒ Erro crÃ­tico no processamento: {e}")
            return {
                "response": "PeÃ§o desculpa, ocorreu um erro inesperado. Podes tentar reformular a tua pergunta?",
                "session_id": session_id,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    async def _direct_llm_response(self, message: str) -> str:
        """Resposta direta do LLM sem ferramentas"""
        try:
            system_msg = SystemMessage(content="""Ã‰s o Ethic Companion, especializado em Ã©tica e desenvolvimento pessoal. 
Responde de forma empÃ¡tica, reflexiva e em portuguÃªs.""")
            
            human_msg = HumanMessage(content=message)
            
            response = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: self.llm.invoke([system_msg, human_msg])
            )
            
            return response.content
            
        except Exception as e:
            logger.error(f"âŒ Erro na resposta direta do LLM: {e}")
            return "Desculpa, tive dificuldades em processar a tua mensagem. Podes tentar novamente?"
    
    def _fallback_response(self, message: str) -> str:
        """Resposta de fallback quando nenhum LLM estÃ¡ disponÃ­vel"""
        return """OlÃ¡! Sou o Ethic Companion e estou aqui para ajudar com questÃµes Ã©ticas e reflexÃµes pessoais.

Atualmente estou em modo limitado, mas posso oferecer algumas sugestÃµes bÃ¡sicas:

ğŸ¤” **Para dilemas Ã©ticos**: Considera os princÃ­pios de autonomia, beneficÃªncia, nÃ£o-maleficÃªncia e justiÃ§a.

ğŸ’­ **Para reflexÃ£o pessoal**: Pergunta-te: "Quais sÃ£o os meus valores fundamentais?" e "Como posso alinhar as minhas aÃ§Ãµes com esses valores?"

ğŸŒ± **Para crescimento**: Pequenos passos consistentes sÃ£o mais eficazes que grandes mudanÃ§as esporÃ¡dicas.

Podes reformular a tua pergunta ou aguardar que o sistema seja totalmente restaurado."""
    
    def _extract_tools_used(self, agent_result: Dict) -> List[str]:
        """Extrai ferramentas usadas do resultado do agente"""
        tools_used = []
        
        # Esta implementaÃ§Ã£o depende da estrutura especÃ­fica do LangChain
        # Pode precisar de ajustes baseados na versÃ£o
        if "intermediate_steps" in agent_result:
            for step in agent_result["intermediate_steps"]:
                if hasattr(step, 'tool') and step.tool:
                    tools_used.append(step.tool)
        
        return tools_used
    
    def _get_llm_type(self) -> str:
        """Identifica o tipo de LLM em uso"""
        if not self.llm:
            return "none"
        
        if "openai" in str(type(self.llm)).lower():
            return "openai"
        elif "google" in str(type(self.llm)).lower():
            return "gemini"
        else:
            return "unknown"
    
    # IMPLEMENTAÃ‡Ã•ES DAS FERRAMENTAS
    
    def _web_search(self, query: str) -> str:
        """Ferramenta de pesquisa web usando Tavily"""
        try:
            # ImplementaÃ§Ã£o simplificada - expandir conforme necessÃ¡rio
            return f"Resultados de pesquisa para '{query}': [Implementar integraÃ§Ã£o Tavily]"
        except Exception as e:
            return f"Erro na pesquisa web: {e}"
    
    def _ethical_analysis(self, dilemma: str) -> str:
        """Ferramenta de anÃ¡lise Ã©tica estruturada"""
        try:
            analysis = f"""
**AnÃ¡lise Ã‰tica do Dilema:**

**Contexto:** {dilemma}

**Perspetivas Ã‰ticas:**
ğŸ›ï¸ **DeontolÃ³gica (Kant):** Foca no dever e nas regras universais
âš–ï¸ **Consequencialista (Utilitarismo):** Avalia resultados e bem-estar geral  
ğŸŒŸ **Virtudes (AristÃ³teles):** Considera o carÃ¡ter e virtudes morais
ğŸ¤ **Ã‰tica do Cuidado:** Enfatiza relaÃ§Ãµes e responsabilidade

**QuestÃµes para ReflexÃ£o:**
- Quais sÃ£o os stakeholders envolvidos?
- Que valores estÃ£o em conflito?
- Quais as consequÃªncias de cada opÃ§Ã£o?
- Que princÃ­pios Ã©ticos se aplicam?

**PrÃ³ximos Passos:** Considera estas perspetivas e identifica a tua intuiÃ§Ã£o moral inicial.
"""
            return analysis
        except Exception as e:
            return f"Erro na anÃ¡lise Ã©tica: {e}"
    
    def _personal_reflection(self, topic: str) -> str:
        """Ferramenta para facilitar reflexÃ£o pessoal"""
        try:
            reflection = f"""
**ReflexÃ£o Pessoal sobre: {topic}**

**Perguntas Orientadoras:**
ğŸ’­ O que sentes quando pensas neste tema?
ğŸ¯ Quais sÃ£o os teus valores relacionados com isto?
ğŸ” Que experiÃªncias passadas influenciam a tua perspetiva?
ğŸŒ± Como gostarias de crescer nesta Ã¡rea?
â­ Que pequeno passo podes dar hoje?

**SugestÃ£o:** Dedica alguns minutos a escrever as tuas respostas. A escrita ajuda a clarificar pensamentos.

**Lembra-te:** NÃ£o hÃ¡ respostas certas ou erradas - apenas a tua verdade pessoal neste momento.
"""
            return reflection
        except Exception as e:
            return f"Erro na reflexÃ£o pessoal: {e}"
    
    def get_agent_status(self) -> Dict[str, Any]:
        """Retorna status do agente para diagnÃ³stico"""
        return {
            "llm_available": self.llm is not None,
            "llm_type": self._get_llm_type(),
            "agent_executor_available": self.agent_executor is not None,
            "tools_count": len(self.tools),
            "tools_available": [tool.name for tool in self.tools],
            "status": "operational" if self.llm else "limited"
        }

# InstÃ¢ncia global do agente
_ai_agent: Optional[EthicCompanionAgent] = None

def get_ai_agent() -> EthicCompanionAgent:
    """
    DependÃªncia FastAPI para obter agente AI
    
    Returns:
        EthicCompanionAgent: InstÃ¢ncia do agente configurado
    """
    global _ai_agent
    
    if _ai_agent is None:
        _ai_agent = EthicCompanionAgent()
    
    return _ai_agent

def reinitialize_agent():
    """Reinicializa o agente (Ãºtil para atualizaÃ§Ãµes de configuraÃ§Ã£o)"""
    global _ai_agent
    _ai_agent = None
    return get_ai_agent()
