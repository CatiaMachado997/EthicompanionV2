#!/usr/bin/env python3
"""
Script de teste para a funÃ§Ã£o get_llm_response
"""

from app.core.llm import get_llm_response

def test_llm():
    print("ğŸ§ª Testando a funÃ§Ã£o get_llm_response...")
    
    try:
        # Teste simples
        print("1. Testando com prompt simples...")
        prompt = "OlÃ¡! Podes dizer-me qual Ã© a capital de Portugal?"
        
        print(f"ğŸ“ Prompt: {prompt}")
        print("â³ Aguardando resposta do Gemini...")
        
        response = get_llm_response(prompt)
        
        print(f"ğŸ¤– Resposta: {response}")
        
        # Teste com pergunta mais complexa
        print("\n2. Testando com pergunta mais complexa...")
        prompt2 = "Explica-me brevemente o que Ã© InteligÃªncia Artificial em 2-3 frases."
        
        print(f"ğŸ“ Prompt: {prompt2}")
        print("â³ Aguardando resposta do Gemini...")
        
        response2 = get_llm_response(prompt2)
        
        print(f"ğŸ¤– Resposta: {response2}")
        
        print("\nğŸ‰ Teste concluÃ­do com sucesso!")
        
    except Exception as e:
        print(f"âŒ Erro durante o teste: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_llm() 